---
title: "Logistic regression tutorial using R"
author: "Leary Ortho Biostats Lab"
date: "11/25/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This tutorial will help you understand logistic regression and the ROC curve analysis.

We will firstly explain the data set which we are going to use, and how to import the data to R. Then, a brief introduction of the logistic regression will be given. When to use logistic regression and how to use it in R will be illustrated. In order to help you interpret the logistic regression result, the odds will be introduced. Finally, we will show you how to do the ROC curve analysis to measure the performance of the logistic regression.

### Import the data

The data set we are using here is from NHANES (National Health and Nutrition Examination Survey). We will just use the data as an example to show logistic regression, so the complex survey design will not be used here. There are 7295 observarions in the data set. The dependent variable is the obesity of the subject. Subject whose BMI is over 30 will denoted with "1" and the subject with a BMI not over 30 will denoted as "0". The independent variables are age , gender and systolic blood pressure (sbp). We are going to predict subject's obesity using the age, gender and sbp variables with logistic regression model.

We highly recommend you to use RStudio for the analysis in this tutorial. RStudio is am integrated development environment (IDE) for R. All the code in this tutorial are case sensitive. 

You can download the data from [Box]() or [Github](). After downloading the data to your computer, you need to find the path of the data file on your computer and import the data to R.

Type the following code in the RStudio console, then a "select file" window will pop up. Use the pop-up window to navigate to the file you want to import and click "Open", the path will display in the console window.

```{r eval=FALSE}
file.choose()
```

Now you have the path of the file, you can use read.csv() function to read the .csv file into R. Type the following code in the RStudio console but replace the path between quotations, with your file path. The new data set will be named "nhanesExample".
```{r echo=FALSE}
nhanesExample = read.csv("C:\\Users\\zs7hm\\Desktop\\rExample.csv")
```
```{r eval=FALSE}
nhanesExample = read.csv("C:\\Users\\zs7hm\\Desktop\\rExample.csv")
```

### Logistic regression

#### When to use logistic regression
Logistic regression is a statistical model uses a logistic function to model a **binary dependent variable**. 
It is used when we want to predict the probability of a binary outcome using independent variables. The binary dependent variable is a categorical variable which has only two possible outcomes. In the data set here, the binary dependent variable is the obesity variable, which has "obesity" denoted as "1" and "not obesity" denoted as "0". 

#### How to do logistic regression in R
Before doing logistic regression, we will firstly split the data into two parts, a training part and a test part. We will use the training data set to build the model, and the we use the test data set to check the performance of the model. In order to reproduce the same result, we will use the set.seed() function to generate the same random number. You can type any number in the parathesis of the set.seed() function. 70% of the whole data set will be allocated for training set, and the rest 30% will be allocated for the test set. 

```{r eval=FALSE}
set.seed(1)
train=nhanesExample[sample(dim(nhanesExample)[1],dim(nhanesExample)[1]*0.7),]
test=nhanesExample[-sample(dim(nhanesExample)[1],dim(nhanesExample)[1]*0.7),]
```
```{r echo=FALSE}
set.seed(1)
train=nhanesExample[sample(dim(nhanesExample)[1],dim(nhanesExample)[1]*0.7),]
test=nhanesExample[-sample(dim(nhanesExample)[1],dim(nhanesExample)[1]*0.7),]
```

We also need to change the gender variable to a categorical variable

```{r eval=FALSE}
nhanesExample$gender = factor(nhanesExample$gender)
```
```{r eval=FALSE}
nhanesExample$gender = factor(nhanesExample$gender)
```

We will use the glm (generalized linear regression) function to do the logistic regression. Logistic regression is just one type of the genrealized linear regression, so in the code we use family = "binomial" to indicate that we are using logistic regression. 

```{r eval=FALSE}
model=glm(obese~ age + gender + sbp, family = "binomial",data=train)
```
```{r echo=FALSE}
model=glm(obese~ age + gender + sbp, family = "binomial",data=train)
```

#### Interpret the result
Let us first explain what is odds. Odds is the ratio of the probability of success and the probability of the failure. In this tutorial, the odds of obesity is probability of obesity over probability of not obesity. Why we need to know this? Because in the logistic regression model, the logarithm of the odds for the value labeled "1" (obesity here) is a linear combination of independent variables.

The summary(model) can print the details for the summary results. In the result of this model, we can see that all variables are significant with a p-value less than 0.05, which means that all parameters are significantly differnt from 0. The estimation of gender2 equals 0.419018 means that being female will increase the log odds of obesity by 0.419018, one year older in age will increase the log odds of obesity by 0.013873, and one unit increase in systolic blood pressure will increase the log odds of obesity by 0.017119. If we take the exponential of the estimation of the parameters, we will see that being female will increase the odds of obesity by 1.5204, one year older will increase the odds of obesity by 1.0140 and one unit increase in systolic blood pressure will increase the odds of obesity by 1.0172.

```{r eval=FALSE}
summary(model)
```
```{r echo=FALSE}
summary(model)
```


### ROC analysis

ROC (Receiver Operating Characteristic) display true positive rate versus false positive of a model. It is used for estimate the performance of a model and select the optimal cutoff point.

Before giving you more information about the ROC curve, let us talk about the "sensitivity" and the "specificity". Sensitivty is the true positive rate and 1 - specificity is the false positive rate. The true positive rate is the proportion that model correctly predict the positive class, and the false positive rate is the proportion that model incorrectly predict the positive class. In our example, the true positive is that the logistic model predict subject is obese and the subject is obese, while the false positive is that the logistic regression model predict the subject is positive but the subject is actually negative. 

Why we need this? Because in the ROC curve, the y axis is the sensitivity, which is the true positive rate, and the x axis is 1 - speciality which is the false positive rate. The ROC curve plots out the sensitivity and specificity for every possible cutoff between 0 and 1 for the logistic regression model. What we want is to push the ROC curve towards the left corner to maximize the area under the curve, which is called AUC (area under the curve). The larger the AUC is, the better the model performs.

An optimal cutoff point can be determined by Youden index. The Youden index J = sensitivity + specificity -1. A value of 1 indicates that there are no false positive or false negative so that the model is perfect. A value of zero indicates that true positive rate equals to false positive rate such that the model predict results just like random guess. The optimal cutoff point which maximize the Youden index J.


```{r eval=FALSE}
cp=multi_cutpointr(nhanesExample,x=c(nhanesExample$age, nhanesExample$gender, nhanesExample$sbp), 
             class=obese)
```






