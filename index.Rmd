---
title: "Logistic regression tutorial using R"
author: "Leary Ortho Biostats Lab"
date: "11/26/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<br/>
<br/>
<br/>

This tutorial will help you understand logistic regression and the ROC curve analysis.

We will firstly explain the data set which we are going to use, and how to import the data to R. Then, a brief introduction of the logistic regression will be given. When to use logistic regression and how to use it in R will be illustrated. Finally, we will show you how to do the ROC curve analysis to measure the performance of the logistic regression.

<br/>

### Import the data

The data set we are using here is from NHANES (National Health and Nutrition Examination Survey). We will just use the data as an example to show logistic regression, so the complex survey design will not be used. There are 7295 observations in the data set. The dependent variable is the obesity of the subject. Subject whose BMI is over 30 will be denoted with "1" and the subject with a BMI not over 30 will be denoted as "0". The independent variables include age, gender and systolic blood pressure (SBP). We are going to predict subject's obesity using the age, gender and SBP variables with logistic regression model.

We highly recommend you to use RStudio for the analysis in this tutorial. RStudio is an integrated development environment (IDE) for R. All the code in this tutorial are case sensitive. 

You can download the data from [Box](https://missouri.box.com/s/s82enrnhdr0nfjr93ym01vns242gu7ow) or [Github](https://raw.githubusercontent.com/zhengyes/logRt/master/rExample.csv). After downloading the data, you need to find the path of the data file on your computer and import the data to R.

Type the following code in the RStudio console, then a "select file" window will pop up. Use the pop-up window to navigate to the file you want to import and click "Open", the path will display in the console window.

```{r eval=FALSE}
file.choose()
```

Now you have the path of the file, you can use read.csv() function to read the .csv file into R. Type the following code in the RStudio console but replace the path between quotations, with your file path. The new data set will be named "nhanesExample".
```{r echo=FALSE}
nhanesExample = read.csv("C:\\Users\\zs7hm\\Desktop\\rExample.csv")
```
```{r eval=FALSE}
nhanesExample = read.csv("C:\\Users\\zs7hm\\Desktop\\rExample.csv")
```

<br/>

### Logistic regression

<br/>

#### When to use logistic regression
Logistic regression is a statistical model uses a logistic function to model a **binary dependent variable**. It is used when we want to predict the probability of a binary outcome using independent variables. The binary dependent variable is a categorical variable which has only two possible outcomes. In the data set here, the binary dependent variable is the obesity variable, which has "obesity" denoted as "1" and "not obesity" denoted as "0". 

#### How to do logistic regression in R
We need to change the gender variable and obese variable to categorical variables.

```{r echo=FALSE}
nhanesExample$gender = factor(nhanesExample$gender)
nhanesExample$obese = factor(nhanesExample$obese)
```
```{r eval=FALSE}
nhanesExample$gender = factor(nhanesExample$gender)
nhanesExample$obese = factor(nhanesExample$obese)
```

Now we will use the glm (generalized linear regression) function to do the logistic regression. Logistic regression is just one type of the generalized linear regression, so in the code we use family = "binomial" to indicate that we are using logistic regression. 

```{r eval=FALSE}
model=glm(obese~ age + gender + sbp, family = "binomial",data=nhanesExample)
```
```{r echo=FALSE}
model=glm(obese~ age + gender + sbp, family = "binomial",data=nhanesExample)
```

#### Interpret the result
Let us first explain what is odds. Odds is the ratio of the probability of success over the probability of the failure. In this tutorial, the odds of obesity is probability of obesity over probability of not obesity. Why we need to know this? Because in the logistic regression model, the logarithm of the odds for the value labeled "1" (obesity) is a linear combination of all independent variables.

In the summary result of this model, we can see that all variables are significant with p-values less than 0.05, which means that all parameters are significantly different from 0. The estimation of gender2 equals 0.3877 means that being female (gender2) will increase the log odds of obesity by 0.3877 compared with male (gender1), one year older in age will increase the log odds of obesity by 0.0141, and one unit increase in systolic blood pressure will increase the log odds of obesity by 0.0183. If we take the exponential of the estimation of the parameters, we will see that being female will increase the odds of obesity by 1.4736 compared with male, one year older will increase the odds of obesity by 1.0142 and one unit increase in systolic blood pressure will increase the odds of obesity by 1.0184.

```{r eval=FALSE}
summary(model)
exp(model$coefficients)
```
```{r echo=FALSE}
summary(model)
exp(model$coefficients)
```

<br/>

### ROC analysis

<br/>

ROC (Receiver Operating Characteristic) curve displays true positive rate versus false positive rate of a fitted model. It can be used for estimating the performance of a model and selecting the optimal cutoff point.

Before giving you further information about the ROC curve, let us talk about some terminologies. 
The true positive means the model predicts subject is obese and the subject is obese. The false positive means the model predicts subject is obese but the subject is actually not obese. The true negative means the model predicts subject not obese and the subject is not obese. The false negative means the model predicts the subject is not obese but the subject is actually obese. Sensitivity is the true positive rate which equals to $\frac{true positive}{true positive + false negative}$, 1 - specificity is the false positive rate which equals to $\frac{false positive}{false positive + true negative}$.

Why we need this? Because in the ROC curve, the y axis is the sensitivity, which is the true positive rate, and the x axis is 1 - specificity which is the false positive rate. The ROC curve plots out the sensitivity and specificity for every possible cutoff between 0 and 1 for the logistic regression model. The area under the ROC curve is called AUC (area under the curve). The larger the AUC is, the better the model performs.

An optimal cutoff point can be determined by Youden index. The Youden index J = sensitivity + specificity -1. A value of 1 indicates that there are no false positive or false negative so that the model is perfect. A value of zero indicates that true positive rate equals to false positive rate such that the model predicts results just like random guess. The optimal cutoff point is the one which maximize the Youden index J.

We need to use the cutpointr package to do the ROC analysis. If you do not have this package on your computer, you need to install it firstly, just type the following code in the RStudio console, and the package will be installed automatically.

```{r eval=FALSE}
install.package("cutpointr")
```

In the ROC plot, the ROC curve is above the diagonal line which implies good classification result. The point on the ROC curve has the corresponding sensitivity and specificity which lead to the optimal Youden's index cutoff point. In the code, x is the fitted values, and class is the original binary outcomes.

```{r eval=FALSE}
library(cutpointr)
# create a data frame contains all information about the ROC curve analysis
# x = logistic regression model predicted values for obesity
# class = original values for obesity
cp <- cutpointr(x=model$fitted.values, class=nhanesExample$obese, metric = youden) 
# plot the ROC curve
plot_roc(cp)
```

```{r,echo=FALSE, message=FALSE}
library(cutpointr)
# create a data frame contains all information about the ROC curve analysis
# x = logistic regression model predicted values for obesity
# class = original values for obesity
cp <- cutpointr(x=model$fitted.values, class=nhanesExample$obese, metric = youden) 
# plot the ROC curve
plot_roc(cp)
```


The AUC = **0.6886**, it can be used as a standard to compare performances of different models. The higher the AUC value, the better the model is at predicting not obese as not obese and obese as obese.
```{r eval=FALSE}
# display the AUC value
auc(cp)
```
```{r echo=FALSE}
# display the AUC value
auc(cp)
```


The Youden's index shows that the optimal threshold is **0.2532**. Therefore, for the predicted probability of obesity, values below 0.2532 become 0 (not obese) and values above 0.2532 become 1 (obese). For this threshold, the fitted model has the largest difference between its true positive rate and false positive rate, which maximize the Youden's J statistic.
```{r eval=FALSE}
# show the optimal cut point by maximizing Youden's index
unlist(summary(cp)$confusion_matrix)[1]
```
```{r echo=FALSE}
# show the optimal cut point by Youden's index
unlist(summary(cp)$confusion_matrix)[1]
```

<br/>
<br/>
<br/>